# LoL-MetaScraper: Competitive Intelligence ETL & Scraper

## üìå Descripci√≥n General

**LoL-MetaScraper** es un sistema automatizado de inteligencia competitiva basado en la extracci√≥n de datos en tiempo real (Web Scraping). Funciona como un motor de soporte anal√≠tico dise√±ado para optimizar la toma de decisiones mediante estad√≠stica pura (Winrates, Banrates, Sinergias y Counters).

El sistema extrae, normaliza e inyecta m√©tricas din√°micas directamente en una base de datos en la nube (Google Sheets), que act√∫a como cerebro estrat√©gico del usuario final.

> **ü§ñ Nota sobre el desarrollo asistido por IA:**
> La concepci√≥n del proyecto, el dise√±o de la arquitectura ETL, la l√≥gica de normalizaci√≥n de datos y el flujo de trabajo (desde la extracci√≥n hasta el volcado en Sheets) son de mi autor√≠a. Para la redacci√≥n de la sintaxis pura de Python y la construcci√≥n √°gil de la interfaz gr√°fica, me he apoyado en Inteligencia Artificial. Mi rol en este proyecto es el de **Arquitecto de Software y Datos**, enfoc√°ndome en resolver el problema y estructurar la soluci√≥n algor√≠tmica de forma eficiente.

## ‚öôÔ∏è Arquitectura del Sistema (ETL & GUI)

El proyecto utiliza una arquitectura de procesamiento en segundo plano con interfaz gr√°fica as√≠ncrona:

### 1. Interfaz Gr√°fica (GUI) y Concurrencia
* **Dashboard Tkinter:** Interfaz de usuario completa con visor de m√©tricas en tiempo real (`Treeview`), barra de progreso y consola de *logs*.
* **Procesamiento As√≠ncrono:** Uso de `threading` y `queue` para aislar el proceso pesado de *scraping* del hilo principal de la interfaz, garantizando una experiencia de usuario fluida sin cuelgues.

### 2. Extract (Web Scraping H√≠brido)
* **Motor Selenium Optimizado:** Configuraci√≥n del WebDriver con argumentos *anti-bot* (`AutomationControlled`) y bloqueo de carga de im√°genes para maximizar la velocidad de respuesta.
* **Parseo HTML con BeautifulSoup:** Una vez que Selenium resuelve el DOM, BeautifulSoup extrae eficientemente las tablas de *counters* y *winrates*.
* **Manejo de Excepciones Din√°mico:** L√≥gica de reintentos y mapeo predictivo de URLs (`SLUG_MAPPING`) para campeones con nomenclaturas irregulares.

### 3. Transform (Data Cleaning)
* **Normalizaci√≥n de Strings:** Estandarizaci√≥n de nombres extra√≠dos de la web (limpieza de caracteres especiales y espacios) para que coincidan un√≠vocamente con la nomenclatura de la base de datos de destino (`OUTPUT_NORMALIZATION`).

### 4. Load (Google Sheets API)
* **Integraci√≥n con GSpread:** Conexi√≥n mediante Service Accounts de Google Cloud (`credentials.json`) para lectura y escritura masiva mediante Pandas DataFrame.
* **Auto-Backup de Seguridad:** El sistema clona autom√°ticamente la hoja de destino en la nube (`worksheet.duplicate`) creando un respaldo con *timestamp* antes de sobrescribir cualquier dato en producci√≥n.

## üõ†Ô∏è Stack Tecnol√≥gico
* **Lenguaje:** Python 3.8+
* **Frontend:** `tkinter`, `ttk`
* **Scraping:** `selenium`, `webdriver_manager`, `beautifulsoup4`
* **Procesamiento y API:** `pandas`, `gspread`
* **Concurrencia:** `threading`, `queue`

## üöÄ Instalaci√≥n y Despliegue

1. Clonar el repositorio.
2. Asegurar la instalaci√≥n de las dependencias requeridas (ver `requirements.txt`).
3. **Configuraci√≥n de Google Cloud (CR√çTICO):**
   * Obtener el archivo JSON de credenciales de una Service Account (Google Cloud Platform).
   * Renombrarlo a `credentials.json` y ubicarlo en la ra√≠z del proyecto.
   * Otorgar permisos de "Editor" en el Google Sheet al email de la Service Account.
4. Ejecutar el proyecto mediante el archivo `launcher.bat` (que automatiza el inicio) o lanzando `python update_lol_data.py`.

---
*Desarrollado por Iv√°n Garc√≠a Miranda.*
